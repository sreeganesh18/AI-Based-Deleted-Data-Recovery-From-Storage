---
phase: 02-models
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [dataset/loader.py, dataset/noise.py, dataset/fragmenter.py, utils/training.py, tests/test_loader.py, tests/test_noise.py, tests/test_fragmenter.py]
autonomous: true
requirements: [DATA-02, TRAIN-01]

must_haves:
  truths:
    - "Source files (JPEG/PDF) can be split into 512-byte fragment blocks"
    - "Can load a directory of fragments as a PyTorch Dataset"
    - "Can generate noisy variants of fragments for autoencoder training"
    - "Base training utility exists for handling loops and checkpoints"
  artifacts:
    - path: "dataset/fragmenter.py"
      provides: "Utility to split source files into 512-byte chunks"
    - path: "dataset/loader.py"
      provides: "FragmentDataset class"
    - path: "dataset/noise.py"
      provides: "NoiseGenerator class with bit-flip and masking"
    - path: "utils/training.py"
      provides: "Re-usable Trainer class"
  key_links:
    - from: "dataset/fragmenter.py"
      to: "dataset/fragments/"
      via: "file generation"
    - from: "dataset/loader.py"
      to: "torch.utils.data.Dataset"
      via: "inheritance"
---

<objective>
Implement the data collection/preprocessing pipeline and core training utilities required for the AI models.

Purpose: Provide consistent data loading, fragmenting, and noise-injection mechanisms for both classification and denoising tasks.
Output: Fragmenter utility, dataset loader, noise generator, and training scaffold.
</objective>

<tasks>

<task type="auto">
  <name>Task 1: Implement Fragmenter Utility</name>
  <files>dataset/fragmenter.py, tests/test_fragmenter.py</files>
  <action>
    Create a `Fragmenter` class in `dataset/fragmenter.py`.
    - Accept source directory (JPEG/PDF) and destination directory.
    - Split each file into contiguous 512-byte blocks.
    - Save each block as a separate file (e.g., `[filename]_frag[index].bin`).
    - Organize fragments into subdirectories by type (e.g., `dataset/fragments/jpeg/`).
    - Create `tests/test_fragmenter.py` to verify splitting logic and file counts.
  </action>
  <verify>pytest tests/test_fragmenter.py</verify>
  <done>Fragmenter correctly splits files into 512-byte chunks and organizes them by type.</done>
</task>

<task type="auto">
  <name>Task 2: Implement FragmentDataset & DataAugmentation</name>
  <files>dataset/loader.py, tests/test_loader.py</files>
  <action>
    Create a PyTorch `FragmentDataset` class in `dataset/loader.py`.
    - Accept a root directory of fragments.
    - Implement `__getitem__` to read 512-byte blocks and return normalized tensors (0.0 to 1.0).
    - Map file types to integer labels (e.g., JPEG=0, PDF=1, OTHER=2) based on directory structure.
    - Create a test `tests/test_loader.py` to verify loading logic and tensor shapes.
  </action>
  <verify>pytest tests/test_loader.py</verify>
  <done>Dataset successfully loads fragments and returns correctly shaped normalized tensors.</done>
</task>

<task type="auto">
  <name>Task 3: Implement NoiseGenerator for DAE</name>
  <files>dataset/noise.py, tests/test_noise.py</files>
  <action>
    Create a `NoiseGenerator` class in `dataset/noise.py`.
    - Implement `add_bit_flip_noise(tensor, p=0.01)` to randomly flip bits in the fragment.
    - Implement `add_masking_noise(tensor, length=32)` to zero-out a random contiguous segment of the fragment.
    - Create a test `tests/test_noise.py` to verify noise patterns are correctly applied.
  </action>
  <verify>pytest tests/test_noise.py</verify>
  <done>Noise generator can modify tensors with specified noise patterns.</done>
</task>

<task type="auto">
  <name>Task 4: Create Trainer Utility Scaffold</name>
  <files>utils/training.py</files>
  <action>
    Implement a `Trainer` class in `utils/training.py` to manage model training.
    - Include methods for: `train_epoch`, `validate_epoch`, `save_checkpoint`, and `load_checkpoint`.
    - Support both classification (CrossEntropyLoss) and reconstruction (MSELoss) loss functions.
    - Integrate with basic logging for tracking metrics.
  </action>
  <verify>python -c "from utils.training import Trainer; print('Trainer class ready')"</verify>
  <done>Trainer class exists and can be initialized with a model, optimizer, and loss function.</done>
</task>

</tasks>

<success_criteria>
- `Fragmenter` correctly splits source files into 512-byte blocks.
- `FragmentDataset` returns (1, 512) normalized tensors.
- `NoiseGenerator` produces modified tensors that differ from the original.
- `Trainer` class can handle a basic training loop with dummy data.
</success_criteria>
