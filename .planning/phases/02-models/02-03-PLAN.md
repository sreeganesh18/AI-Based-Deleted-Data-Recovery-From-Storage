---
phase: 02-models
plan: 03
type: execute
wave: 2
depends_on: [01]
files_modified: [models/autoencoder.py, scripts/train_autoencoder.py, tests/test_autoencoder.py]
autonomous: true
requirements: [AE-01, TRAIN-01]

must_haves:
  truths:
    - "Autoencoder architecture uses 1D-Convolutional layers for encoder/decoder"
    - "Training script incorporates noise injection for denoising"
    - "Reconstruction loss decreases over epochs on dummy data"
  artifacts:
    - path: "models/autoencoder.py"
      provides: "FragmentAutoencoder class"
    - path: "scripts/train_autoencoder.py"
      provides: "CLI to train the denoising autoencoder"
  key_links:
    - from: "models/autoencoder.py"
      to: "dataset/noise.py"
      via: "data corruption for training"
    - from: "scripts/train_autoencoder.py"
      to: "utils/training.py"
      via: "training management"
---

<objective>
Implement the 1D-Convolutional Denoising Autoencoder for fragment repair and the corresponding training script.

Purpose: Reconstruct corrupted or noisy 512-byte fragments.
Output: FragmentAutoencoder model and train_autoencoder.py script.
</objective>

<tasks>

<task type="auto">
  <name>Task 1: Implement 1D-Convolutional Autoencoder</name>
  <files>models/autoencoder.py, tests/test_autoencoder.py</files>
  <action>
    Refactor `models/autoencoder.py` with 1D-Conv layers.
    - Encoder: 3x Conv1D layers with stride 2 for downsampling.
    - Decoder: 3x ConvTranspose1D layers for upsampling.
    - Input/Output: (1, 512) tensor.
    - Use Sigmoid activation on the final output layer to keep bytes in [0, 1].
    - Create `tests/test_autoencoder.py` to verify input-output shape match.
  </action>
  <verify>pytest tests/test_autoencoder.py</verify>
  <done>Autoencoder produces (1, 512) output for a (1, 512) input.</done>
</task>

<task type="auto">
  <name>Task 2: Create Autoencoder Training Script</name>
  <files>scripts/train_autoencoder.py</files>
  <action>
    Implement `scripts/train_autoencoder.py`.
    - Use `argparse` for hyperparameters.
    - Use `FragmentDataset` and `NoiseGenerator`.
    - The training loop should:
        1. Get original fragment.
        2. Apply noise using `NoiseGenerator`.
        3. Pass noisy fragment to Autoencoder.
        4. Calculate MSELoss against original fragment.
    - Save best model to `models/checkpoints/autoencoder_best.pth`.
  </action>
  <verify>python scripts/train_autoencoder.py --epochs 1 --batch-size 4 --data-dir dataset/fragments/ (with dummy data)</verify>
  <done>Training script executes and produces a denoising model checkpoint.</done>
</task>

</tasks>

<success_criteria>
- `FragmentAutoencoder` preserves the 512-byte dimension.
- `train_autoencoder.py` successfully executes a training epoch with noise injection.
- Reconstructed fragments can be saved and visually compared (optional logging).
</success_criteria>
